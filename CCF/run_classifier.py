# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wa0cyT8BDgWLEItUkIj3QZLsOUwS8nKP
"""

# !pip install transformers
import os
import torch 
import numpy as np
import pandas as pd
from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup
from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler

PATH = '/content/CCF_QA/'
EPOCHS = 5
BATCH_SIZE = 16
MAX_LENGTH = 280
LEARNING_RATE = 1e-5

model = BertModel.from_pretrained('hfl/chinese-bert-wwm')
tokenizer = BertTokenizer.from_pretrained('hfl/chinese-bert-wwm')

def load_data(train_test='train'):
    D = {}
    with open(os.path.join(PATH, train_test, train_test + '.query.tsv')) as f:
        for l in f:
            span = l.strip().split('\t')
            D[span[0]] = {'query': span[1], 'reply': []}

    with open(os.path.join(PATH, train_test, train_test + '.reply.tsv')) as f:
        for l in f:
            span = l.strip().split('\t')
            if len(span) == 4:
                q_id, r_id, r, label = span
            else:
                label = None
                q_id, r_id, r = span
            D[q_id]['reply'].append([r_id, r, label])
    d = []
    for k, v in D.items():
        q_id = k
        q = v['query']
        reply = v['reply']

        for r in reply:
            r_id, rc, label = r

            d.append([q_id, q, r_id, rc, label])
    return d

train = load_data(train_test='train')
test = load_data(train_test='test')
print('train example', train[0:5])
print('test example', test[0:5])

def process(data, flag='train', threshold=None):

  '''
  Parameters@
    data: list, a matrix which dimensional equals to two
    flag: bool, indecate whether is train data
    threshold: float, use to split train data, range from 0 to 1
  
  Returns@
      A dataloader of train set and valid set while flag=1, otherwise, test set
  '''

  if threshold and (threshold<=0 or threshold>=1):
    print
    print('NumericalError: threshold out of range, a correct value must between (0,1)')
  else:
    threshold = 0.8

    
  input_ids = []
  token_type_ids = []
  labels = []
  
  for text in data:
    encode_dic = tokenizer.encode_plus(
      text=text[1],
      text_pair=text[3],
      max_length=256,
      padding='max_length',
      truncation=True,
      pad_to_multiple_of=True,  
      add_special_tokens=True,
      return_token_type_ids=True,  
      return_tensors='pt'
    )
    input_ids.append(encode_dic['input_ids'])
    token_type_ids.append(encode_dic['token_type_ids'])

  input_ids = torch.cat(input_ids, dim=0)
  
  token_type_ids = torch.cat(token_type_ids, dim=0)
    
  # pack up and transform to dataloader, which is feeded to model
  if flag == 'train':
    for text in data:
      labels.append(int(text[4]))
    labels = torch.tensor(labels)

    train_data = TensorDataset(input_ids, token_type_ids, labels)

    train_size = int(threshold * len(train_data))
    val_size = len(train_data) - train_size
    train_data, val_data = random_split(train_data, [train_size, val_size])

    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, 
                              sampler=RandomSampler(train_data))
    val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, 
                            sampler=SequentialSampler(val_data))
    
    return train_loader, val_loader

  else:
    predict_data = TensorDataset(input_ids, token_type_ids)
    predict_dataloader = DataLoader(predict_data, batch_size=BATCH_SIZE, 
                                    sampler=SequentialSampler(predict_data))
    
    return predict_dataloader


    
train_dataloader, val_dataloader = process(train)
predict_dataloader = process(test, flag='test')













